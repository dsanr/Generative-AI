{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc216362-c981-4b29-8859-c5b0a0ba8ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import langchain\n",
    "import langchain_community\n",
    "import langchain_text_splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "85d4c8f1-9f58-42a5-b338-615c7a4a9fde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.6'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b6b779b-2e64-48dc-9053-f07d5b89335f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.2.6'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "langchain_community.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "952f9138-e0ff-4dc1-a39d-184974b6d267",
   "metadata": {
    "id": "cKlax-updNW-"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec3bc217-411c-446c-85d2-02f10a1d6d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd460fb8-0d83-46a2-8fe4-a89aaac4f798",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv('/home/santhosh/Projects/courses/Pinnacle/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7635b21b-54d4-452e-bca2-60168dc53e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = os.environ['OPENAI_API_KEY']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159d21fc-99d3-4d8d-a741-35a69239e782",
   "metadata": {},
   "source": [
    "https://github.com/langchain-ai/langchain/blob/master/libs/text-splitters/langchain_text_splitters/base.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b682b-e322-4942-bf12-48fc459442e3",
   "metadata": {},
   "source": [
    "# Character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "17343629-4abc-4c12-a80a-38cad7e3e108",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import UnstructuredMarkdownLoader, UnstructuredPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4473ef55-a619-4f5d-a2c8-eaa0489f6c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import CharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2374fadc-4e40-41c0-85cc-ac3aeb5381e3",
   "metadata": {},
   "source": [
    "https://info.email.online.hbs.edu/strategy-formulation-ebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d090385-82e8-42ef-9374-a0d5db280d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader('how-to-formulate-successful-business-strategy.pdf', mode='single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "id": "a44e600f-7c69-4ecd-860c-16472fb8112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "id": "a4284deb-77df-4005-b833-6b10dd91a2a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "id": "2cf9cb4d-761b-4fd7-b7fc-edc83cba8825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'how-to-formulate-successful-business-strategy.pdf'}"
      ]
     },
     "execution_count": 429,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "id": "d3d1687d-0c9f-4982-bc5a-33052553d9ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter(\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=0,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "id": "4323ee8a-4dbc-4090-9d73-17d88a1c4b1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Created a chunk of size 535, which is longer than the specified 500\n",
      "Created a chunk of size 688, which is longer than the specified 500\n"
     ]
    }
   ],
   "source": [
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "id": "b407e39e-1766-4196-924f-ff39f8e20da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "id": "1ddc37a5-984d-43dd-8e0d-644a30fa095b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'how-to-formulate-successful-business-strategy.pdf'}"
      ]
     },
     "execution_count": 433,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[40].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "id": "38ec2cb2-db3c-4e3c-899e-a275bf1e94f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.randint(1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 444,
   "id": "ebc12ea8-9372-4d38-a74c-98649d59d022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "688\n",
      "4. Set and Effectively Communicate Goals As discussed in the previous section, selecting strategic goals is an important step of strategy formulation. Just as important is the ability to effectively communicate those goals to your organization. Research outlined in the Harvard Business Review shows that, on average, 95 percent of employees donâ€™t understand their companyâ€™s strategyâ€”a staggering statistic, considering that successful strategy execution requires organization-wide effort. Crafting a strategy is crucial, but it canâ€™t be successful unless itâ€™s effectively and artfully communicated to all employees so they feel empowered and responsible for reaching the companyâ€™s goals.\n",
      "495\n",
      "5. Think of Strategy as an Ongoing Process\n",
      "Once youâ€™ve formulated and communicated a strategic plan, it can be tempting to assume the strategic planning process is complete. According to HBS Professor Clayton Christensen, strategy is a continual process of development. In the online course Disruptive Strategy, Christensen notes that in a study of HBS graduates who started businesses, 93 percent of those with successful strategies evolved and pivoted away from their original strategic plans.\n"
     ]
    }
   ],
   "source": [
    "for i in texts[48:50]:\n",
    "    print(len(i.page_content))\n",
    "    print(i.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bdff87-9a62-4cfe-8d82-30aa48e199df",
   "metadata": {},
   "source": [
    "# Recursive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9141caa-44b9-4489-83a0-4e655f9fa973",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "47a43c13-1ca6-4571-8da8-89e9812dd95e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader('how-to-formulate-successful-business-strategy.pdf', mode='single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "60ad55e8-ca83-4ffd-bdc0-ce71ddc04397",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "162d1405-1251-4823-985d-3dfca51c618c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "8e2c72b1-c337-4c4e-a7cb-138f57f5943c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'how-to-formulate-successful-business-strategy.pdf'}"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "id": "6d882eb7-e3e2-4dca-a2ee-79af0f8a98e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "recursive_splitter = RecursiveCharacterTextSplitter(separators=[\"\\n\\n\", \"\\n\", r\"(?<=[.?!])\\s+\"], \n",
    "                                                    keep_separator=False, is_separator_regex=True,\n",
    "                                                    chunk_size=30, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "id": "c011ad34-26fd-4d05-bd11-374bf9a4bec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = recursive_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "id": "0fd7cc42-d7c1-439b-af9e-f02cc3525a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "293"
      ]
     },
     "execution_count": 458,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "id": "10252c88-859a-4322-88c7-7d06713c4ce5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'how-to-formulate-successful-business-strategy.pdf'}"
      ]
     },
     "execution_count": 417,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[10].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "id": "c1834b5a-ec97-4e25-a88f-9db60dff324c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "47\n",
      "How to Formulate a Successful Business Strategy\n",
      "8\n",
      "Contents\n"
     ]
    }
   ],
   "source": [
    "for text in texts[:2]:\n",
    "    print(len(text.page_content))\n",
    "    print(text.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "id": "c8afc391-7dbd-4b0f-b1ad-325c486ae92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "175\n",
      "According to a survey by Bridges Business Consultancy, just 68 percent of professionals believe their organization is good at developing strategyâ€”down from 80 percent in 2012.\n",
      "71\n",
      "Formulating a strong strategy doesnâ€™t need to be daunting or difficult.\n",
      "70\n",
      "Here are five factors to consider for successful strategy formulation.\n",
      "21\n",
      "1. Start with Purpose\n",
      "21\n",
      "FORMULATION FRAMEWORK\n",
      "253\n",
      "When setting out to create a winning strategy, the first question to ask yourself is, â€œWhatâ€™s my organizationâ€™s purpose?â€ In Sustainable Business Strategy, Henderson discusses the importance of starting with purpose when building your business strategy.\n"
     ]
    }
   ],
   "source": [
    "for text in texts[123:129]:\n",
    "    print(len(text.page_content))\n",
    "    print(text.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cd42318-43f1-4b2f-a942-65a0c6c7a6c1",
   "metadata": {},
   "source": [
    "# Token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf1e253-693d-47f2-80e4-81266153bd26",
   "metadata": {},
   "source": [
    "https://github.com/openai/tiktoken/blob/main/tiktoken/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "726f016e-a097-43df-9bb5-a09e44a76363",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import TokenTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7a6fa6de-3df4-4904-92e1-39fc1c21ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader('how-to-formulate-successful-business-strategy.pdf', mode='single')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "90aff412-0ace-4a42-bd1a-066727997e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d366e1c-c790-4b8a-9241-a9fa552f05a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "105db488-bc48-4db2-aea2-793804f7802a",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name='o200k_base', \n",
    "    separators=[\"\\n\\n\", \"\\n\", r\"(?<=[.?!])\\s+\"], \n",
    "    keep_separator=False,\n",
    "    is_separator_regex=True,\n",
    "    chunk_size=10, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "ff25e690-eb15-4c08-b244-ef108e77c610",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = CharacterTextSplitter.from_tiktoken_encoder(\n",
    "    encoding_name='o200k_base',\n",
    "    separator=\"\\n\",\n",
    "    chunk_size=50,\n",
    "    chunk_overlap=0,\n",
    "    is_separator_regex=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "id": "dbad0348-6a4d-456f-8416-c5d4edab83b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = TokenTextSplitter(encoding_name='o200k_base', chunk_size=50, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9950b81c-da1b-4a1b-b7e1-c738ee485be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51b97eda-195f-4c13-bdbf-c939c841d770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aff52213-7d15-49b0-87e6-9fdb5aa80f91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57\n",
      "How to Formulate a Successful Business Strategy\n",
      "\n",
      "Contents\n",
      "53\n",
      "3 What Is Strategic Planning and Why Is It Important?\n",
      "43\n",
      "6 Setting and Prioritizing\n",
      "\n",
      "Strategic Goals\n",
      "43\n",
      "10 Keys to Successful Strategy\n",
      "\n",
      "Formulation\n"
     ]
    }
   ],
   "source": [
    "for i in texts[:4]:\n",
    "    print(len(i.page_content))\n",
    "    print(i.page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89366627-2c7a-4853-b6a7-bce89defd696",
   "metadata": {},
   "source": [
    "# HTML Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7db040d-93c8-49b2-9253-77d66ca20c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, HTMLHeaderTextSplitter, HTMLSectionSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1967586c-e7fd-4f18-afc3-df20c077bd22",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"h3\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0682e6b9-d1e1-465b-b367-5f5106f82c2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_splitter = HTMLHeaderTextSplitter(headers_to_split_on, return_each_element=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d9e58c76-f392-4ec9-baa2-3586e238bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_header_splits = html_splitter.split_text_from_url('https://diataxis.fr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f485ab20-fe2a-42a5-80a8-89000029402f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(html_header_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cd29e256-8ec9-4522-8429-19d38b7c2206",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Header 1': 'DiÃ¡taxisÂ¶'}\n",
      "{'Header 1': 'DiÃ¡taxisÂ¶', 'Header 2': 'ContentsÂ¶'}\n"
     ]
    }
   ],
   "source": [
    "for header in html_header_splits[20:22]:\n",
    "    print(header.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c31a5655-a689-4dce-8b24-a8d680dcf115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "293\n",
      "page_content='DiÃ¡taxis identifies four distinct needs, and four corresponding forms of documentation - tutorials, how-to guides, technical reference and explanation. It places them in a systematic relationship, and proposes that documentation should itself be organised around the structures of those needs.' metadata={'Header 1': 'DiÃ¡taxisÂ¶'}\n",
      "137\n",
      "page_content='DiÃ¡taxis solves problems related to documentation content (what to write), style (how to write it) and architecture (how to organise it).' metadata={'Header 1': 'DiÃ¡taxisÂ¶'}\n",
      "340\n",
      "page_content='As well as serving the users of documentation, DiÃ¡taxis has value for documentation creators and maintainers. It is light-weight, easy to grasp and straightforward to apply. It doesnâ€™t impose implementation constraints. It brings an active principle of quality to documentation that helps maintainers think effectively about their own work.' metadata={'Header 1': 'DiÃ¡taxisÂ¶'}\n",
      "86\n",
      "page_content='This website is divided into two main sections, to help apply and understand DiÃ¡taxis.' metadata={'Header 1': 'DiÃ¡taxisÂ¶', 'Header 2': 'ContentsÂ¶'}\n",
      "81\n",
      "page_content='Start here. These pages will help make immediate, concrete sense of the approach.' metadata={'Header 1': 'DiÃ¡taxisÂ¶', 'Header 2': 'ContentsÂ¶'}\n",
      "84\n",
      "page_content='Applying DiÃ¡taxis Tutorials How-to guides Reference Explanation The compass Workflow' metadata={'Header 1': 'DiÃ¡taxisÂ¶', 'Header 2': 'ContentsÂ¶'}\n",
      "132\n",
      "page_content='This section explores the theory and principles of DiÃ¡taxis more deeply, and sets forth the understanding of needs that underpin it.' metadata={'Header 1': 'DiÃ¡taxisÂ¶', 'Header 2': 'ContentsÂ¶'}\n"
     ]
    }
   ],
   "source": [
    "for header in html_header_splits[18:25]:\n",
    "    print(len(header.page_content))\n",
    "    print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5ccd1e2-fcb4-49ec-ad51-418aa467d568",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ea89d817-6b3f-48ef-8efc-0e4c578e464d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "r = requests.get('https://diataxis.fr/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8767d048-be50-436b-ac21-e51a004fa345",
   "metadata": {},
   "outputs": [],
   "source": [
    "sections_to_split_on = [\n",
    "    (\"h1\", \"Header 1\"),\n",
    "    (\"h2\", \"Header 2\"),\n",
    "    (\"p\", \"section\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8848751d-e981-472a-b2da-12c31e563c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_splitter = HTMLSectionSplitter(sections_to_split_on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "acf0fffe-18b0-4d85-811b-410840506edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_section_splits = html_splitter.split_text(r.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1faae608-484d-4067-91d7-bfadb7edb5bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(html_section_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6c582c7f-979c-426b-bfdf-e74e95b7d266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "page_content='DiÃ¡taxis Â¶' metadata={'Header 1': 'DiÃ¡taxisÂ¶'}\n",
      "59\n",
      "page_content='A systematic approach to technical documentation authoring.' metadata={'section': 'A systematic approach to technical documentation authoring.'}\n",
      "60\n",
      "page_content='DiÃ¡taxis is a way of thinking about and doing documentation.' metadata={'section': 'DiÃ¡taxis is a way of thinking about and doing documentation.'}\n",
      "148\n",
      "page_content='It prescribes approaches to content, architecture and form that emerge from a systematic approach to understanding the needs of documentation users.' metadata={'section': 'It prescribes approaches to content, architecture and form that emerge from a systematic approach to understanding the needs of documentation users.'}\n",
      "90\n",
      "page_content='DiÃ¡taxis , from the Ancient Greek Î´á¿á¾°ÌÏ„á¾°Î¾á¿Ï‚:  dia  (â€œacrossâ€) and  taxis  (â€œarrangementâ€).' metadata={'section': 'DiÃ¡taxis, from the Ancient Greek Î´á¿á¾°ÌÏ„á¾°Î¾á¿Ï‚: dia (â€œacrossâ€) and taxis (â€œarrangementâ€).'}\n"
     ]
    }
   ],
   "source": [
    "for section in html_section_splits[1:6]:\n",
    "    print(len(section.page_content))\n",
    "    print(section)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d3072e-494b-473c-9abd-1fe65e327c24",
   "metadata": {},
   "source": [
    "# Markdown Header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "815d153b-628b-4717-b448-7a9088825c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "508cbffc-725a-422a-9f29-80969ab87dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"README.md\") as f:\n",
    "    best_of_ml = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "6f69664c-50af-4c78-b7bb-cd1d939f4ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers_to_split_on = [\n",
    "    (\"#\", \"Header 1\"),\n",
    "    (\"##\", \"Header 2\"),\n",
    "    # (\"-\", \"Header 3\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "14ac7193-2081-47b9-878b-e75be64eec04",
   "metadata": {},
   "outputs": [],
   "source": [
    "markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on, return_each_line=False)\n",
    "md_header_splits = markdown_splitter.split_text(best_of_ml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5b056829-3c99-45a2-a30f-7c1406011aad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(md_header_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "35e4aade-b55e-4dc4-840b-5c4219efe374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Header 2': 'Optical Character Recognition'}"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[20].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "232001f3-5a1d-4540-960a-e3d9c14864f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Header 2': 'Reinforcement Learning'}"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md_header_splits[21].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c19ea59f-3054-464b-a748-21fdf178a2c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27865\n",
      "<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>  \n",
      "_Libraries for image & video processing, manipulation, and augmentation as well as libraries for computer vision tasks such as facial recognition, object detection, and classification._  \n",
      "<details><summary><b><a href=\"https://github.com/python-pillow/Pillow\">Pillow</a></b> (ğŸ¥‡48 Â·  â­ 12K) - Python Imaging Library (Fork). <code><a href=\"https://tldrlegal.com/search?q=PIL\">â—ï¸PIL</a></code></summary>  \n",
      "- [GitHub](https://github.com/python-pillow/Pillow) (ğŸ‘¨ğŸ’» 470 Â· ğŸ”€ 2.1K Â· ğŸ“¦ 1.7M Â· ğŸ“‹ 3.1K - 2% open Â· â±ï¸ 04.07.2024):  \n",
      "```\n",
      "git clone https://github.com/python-pillow/Pillow\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/Pillow) (ğŸ“¥ 90M / month):\n",
      "```\n",
      "pip install Pillow\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/pillow) (ğŸ“¥ 41M Â· â±ï¸ 02.07.2024):\n",
      "```\n",
      "conda install -c conda-forge pillow\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/ultralytics/ultralytics\">ultralytics</a></b> (ğŸ¥‡42 Â·  â­ 26K) - NEW - YOLOv8 in PyTorch ONNX OpenVINO CoreML TFLite. <code><a href=\"http://bit.ly/3pwmjO5\">â—ï¸AGPL-3.0</a></code></summary>  \n",
      "- [GitHub](https://github.com/ultralytics/ultralytics) (ğŸ‘¨ğŸ’» 150 Â· ğŸ”€ 5K Â· ğŸ“¦ 20K Â· ğŸ“‹ 7.7K - 8% open Â· â±ï¸ 04.07.2024):  \n",
      "```\n",
      "git clone https://github.com/ultralytics/ultralytics\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/ultralytics) (ğŸ“¥ 2.5M / month):\n",
      "```\n",
      "pip install ultralytics\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/scikit-image/scikit-image\">scikit-image</a></b> (ğŸ¥‡42 Â·  â­ 5.9K) - Image processing in Python. <code>â—Unlicensed</code></summary>  \n",
      "- [GitHub](https://github.com/scikit-image/scikit-image) (ğŸ‘¨ğŸ’» 660 Â· ğŸ”€ 2.1K Â· ğŸ“¦ 190K Â· ğŸ“‹ 2.6K - 21% open Â· â±ï¸ 03.07.2024):  \n",
      "```\n",
      "git clone https://github.com/scikit-image/scikit-image\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/scikit-image) (ğŸ“¥ 11M / month):\n",
      "```\n",
      "pip install scikit-image\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/scikit-image) (ğŸ“¥ 6.5M Â· â±ï¸ 27.06.2024):\n",
      "```\n",
      "conda install -c conda-forge scikit-image\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/huggingface/pytorch-image-models\">PyTorch Image Models</a></b> (ğŸ¥‡41 Â·  â­ 31K) - The largest collection of PyTorch image encoders /.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/huggingface/pytorch-image-models) (ğŸ‘¨ğŸ’» 140 Â· ğŸ”€ 4.5K Â· ğŸ“¥ 6.8M Â· ğŸ“¦ 32K Â· ğŸ“‹ 890 - 6% open Â· â±ï¸ 28.06.2024):  \n",
      "```\n",
      "git clone https://github.com/rwightman/pytorch-image-models\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/timm) (ğŸ“¥ 4.5M / month):\n",
      "```\n",
      "pip install timm\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/timm) (ğŸ“¥ 180K Â· â±ï¸ 20.06.2024):\n",
      "```\n",
      "conda install -c conda-forge timm\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/pytorch/vision\">torchvision</a></b> (ğŸ¥‡38 Â·  â­ 16K) - Datasets, Transforms and Models specific to Computer Vision. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/pytorch/vision) (ğŸ‘¨ğŸ’» 600 Â· ğŸ”€ 6.7K Â· ğŸ“¥ 38K Â· ğŸ“¦ 21 Â· ğŸ“‹ 3.2K - 24% open Â· â±ï¸ 04.07.2024):  \n",
      "```\n",
      "git clone https://github.com/pytorch/vision\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/torchvision) (ğŸ“¥ 11M / month):\n",
      "```\n",
      "pip install torchvision\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/torchvision) (ğŸ“¥ 1.3M Â· â±ï¸ 11.06.2024):\n",
      "```\n",
      "conda install -c conda-forge torchvision\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/albumentations-team/albumentations\">Albumentations</a></b> (ğŸ¥‡38 Â·  â­ 14K) - Fast and flexible image augmentation library. Paper about.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/albumentations-team/albumentations) (ğŸ‘¨ğŸ’» 140 Â· ğŸ”€ 1.6K Â· ğŸ“¦ 25K Â· ğŸ“‹ 950 - 37% open Â· â±ï¸ 03.07.2024):  \n",
      "```\n",
      "git clone https://github.com/albumentations-team/albumentations\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/albumentations) (ğŸ“¥ 2.1M / month):\n",
      "```\n",
      "pip install albumentations\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/albumentations) (ğŸ“¥ 170K Â· â±ï¸ 27.06.2024):\n",
      "```\n",
      "conda install -c conda-forge albumentations\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/Zulko/moviepy\">MoviePy</a></b> (ğŸ¥‡38 Â·  â­ 12K) - Video editing with Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>  \n",
      "- [GitHub](https://github.com/Zulko/moviepy) (ğŸ‘¨ğŸ’» 160 Â· ğŸ”€ 1.5K Â· ğŸ“¦ 41K Â· ğŸ“‹ 1.5K - 28% open Â· â±ï¸ 27.05.2024):  \n",
      "```\n",
      "git clone https://github.com/Zulko/moviepy\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/moviepy) (ğŸ“¥ 1.1M / month):\n",
      "```\n",
      "pip install moviepy\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/moviepy) (ğŸ“¥ 250K Â· â±ï¸ 16.06.2023):\n",
      "```\n",
      "conda install -c conda-forge moviepy\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/kornia/kornia\">Kornia</a></b> (ğŸ¥‡38 Â·  â­ 9.6K) - Geometric Computer Vision Library for Spatial AI. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/kornia/kornia) (ğŸ‘¨ğŸ’» 260 Â· ğŸ”€ 920 Â· ğŸ“¥ 1.2K Â· ğŸ“¦ 11K Â· ğŸ“‹ 900 - 28% open Â· â±ï¸ 02.07.2024):  \n",
      "```\n",
      "git clone https://github.com/kornia/kornia\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/kornia) (ğŸ“¥ 1.4M / month):\n",
      "```\n",
      "pip install kornia\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/kornia) (ğŸ“¥ 130K Â· â±ï¸ 28.06.2024):\n",
      "```\n",
      "conda install -c conda-forge kornia\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/imageio/imageio\">imageio</a></b> (ğŸ¥‡38 Â·  â­ 1.4K) - Python library for reading and writing image data. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>  \n",
      "- [GitHub](https://github.com/imageio/imageio) (ğŸ‘¨ğŸ’» 110 Â· ğŸ”€ 290 Â· ğŸ“¥ 1.1K Â· ğŸ“¦ 130K Â· ğŸ“‹ 600 - 15% open Â· â±ï¸ 24.06.2024):  \n",
      "```\n",
      "git clone https://github.com/imageio/imageio\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/imageio) (ğŸ“¥ 19M / month):\n",
      "```\n",
      "pip install imageio\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/imageio) (ğŸ“¥ 6.5M Â· â±ï¸ 24.06.2024):\n",
      "```\n",
      "conda install -c conda-forge imageio\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/open-mmlab/mmdetection\">MMDetection</a></b> (ğŸ¥ˆ37 Â·  â­ 29K) - OpenMMLab Detection Toolbox and Benchmark. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/open-mmlab/mmdetection) (ğŸ‘¨ğŸ’» 460 Â· ğŸ”€ 8.4K Â· ğŸ“¦ 2.7K Â· ğŸ“‹ 8.2K - 18% open Â· â±ï¸ 05.02.2024):  \n",
      "```\n",
      "git clone https://github.com/open-mmlab/mmdetection\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/mmdet) (ğŸ“¥ 210K / month):\n",
      "```\n",
      "pip install mmdet\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/opencv/opencv-python\">opencv-python</a></b> (ğŸ¥ˆ37 Â·  â­ 4.3K) - Automated CI toolchain to produce precompiled opencv-python,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>  \n",
      "- [GitHub](https://github.com/opencv/opencv-python) (ğŸ‘¨ğŸ’» 48 Â· ğŸ”€ 790 Â· ğŸ“¦ 410K Â· ğŸ“‹ 780 - 14% open Â· â±ï¸ 17.06.2024):  \n",
      "```\n",
      "git clone https://github.com/opencv/opencv-python\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/opencv-python) (ğŸ“¥ 14M / month):\n",
      "```\n",
      "pip install opencv-python\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/serengil/deepface\">deepface</a></b> (ğŸ¥ˆ36 Â·  â­ 11K) - A Lightweight Face Recognition and Facial Attribute Analysis (Age,.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>  \n",
      "- [GitHub](https://github.com/serengil/deepface) (ğŸ‘¨ğŸ’» 63 Â· ğŸ”€ 1.9K Â· ğŸ“¦ 3.5K Â· ğŸ“‹ 1.1K - 0% open Â· â±ï¸ 03.07.2024):  \n",
      "```\n",
      "git clone https://github.com/serengil/deepface\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/deepface) (ğŸ“¥ 63K / month):\n",
      "```\n",
      "pip install deepface\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/facebookresearch/detectron2\">detectron2</a></b> (ğŸ¥ˆ34 Â·  â­ 29K) - Detectron2 is a platform for object detection, segmentation.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/facebookresearch/detectron2) (ğŸ‘¨ğŸ’» 270 Â· ğŸ”€ 7K Â· ğŸ“¦ 1.9K Â· ğŸ“‹ 3.5K - 11% open Â· â±ï¸ 21.06.2024):  \n",
      "```\n",
      "git clone https://github.com/facebookresearch/detectron2\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/detectron2):\n",
      "```\n",
      "pip install detectron2\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/detectron2) (ğŸ“¥ 310K Â· â±ï¸ 19.05.2024):\n",
      "```\n",
      "conda install -c conda-forge detectron2\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/emcconville/wand\">Wand</a></b> (ğŸ¥ˆ34 Â·  â­ 1.4K) - The ctypes-based simple ImageMagick binding for Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>  \n",
      "- [GitHub](https://github.com/emcconville/wand) (ğŸ‘¨ğŸ’» 100 Â· ğŸ”€ 200 Â· ğŸ“¥ 48K Â· ğŸ“¦ 19K Â· ğŸ“‹ 420 - 4% open Â· â±ï¸ 11.02.2024):  \n",
      "```\n",
      "git clone https://github.com/emcconville/wand\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/wand) (ğŸ“¥ 750K / month):\n",
      "```\n",
      "pip install wand\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/wand) (ğŸ“¥ 55K Â· â±ï¸ 16.06.2023):\n",
      "```\n",
      "conda install -c conda-forge wand\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/deepinsight/insightface\">InsightFace</a></b> (ğŸ¥ˆ33 Â·  â­ 22K) - State-of-the-art 2D and 3D Face Analysis Project. <code>â—Unlicensed</code> <code><img src=\"https://git.io/JLy1X\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/deepinsight/insightface) (ğŸ‘¨ğŸ’» 60 Â· ğŸ”€ 5.2K Â· ğŸ“¥ 3.7M Â· ğŸ“¦ 2.3K Â· ğŸ“‹ 2.4K - 43% open Â· â±ï¸ 02.07.2024):  \n",
      "```\n",
      "git clone https://github.com/deepinsight/insightface\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/insightface) (ğŸ“¥ 320K / month):\n",
      "```\n",
      "pip install insightface\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/facebookresearch/pytorch3d\">PyTorch3D</a></b> (ğŸ¥ˆ33 Â·  â­ 8.5K) - PyTorch3D is FAIRs library of reusable components for.. <code>â—Unlicensed</code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/facebookresearch/pytorch3d) (ğŸ‘¨ğŸ’» 140 Â· ğŸ”€ 1.2K Â· ğŸ“¦ 870 Â· ğŸ“‹ 1.5K - 16% open Â· â±ï¸ 27.06.2024):  \n",
      "```\n",
      "git clone https://github.com/facebookresearch/pytorch3d\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/pytorch3d) (ğŸ“¥ 5.5K / month):\n",
      "```\n",
      "pip install pytorch3d\n",
      "```\n",
      "- [Conda](https://anaconda.org/pytorch3d/pytorch3d) (ğŸ“¥ 220K Â· â±ï¸ 27.06.2024):\n",
      "```\n",
      "conda install -c pytorch3d pytorch3d\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/PaddlePaddle/PaddleSeg\">PaddleSeg</a></b> (ğŸ¥ˆ31 Â·  â­ 8.4K) - Easy-to-use image segmentation library with awesome pre-.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1M\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/PaddlePaddle/PaddleSeg) (ğŸ‘¨ğŸ’» 120 Â· ğŸ”€ 1.6K Â· ğŸ“¦ 1.2K Â· ğŸ“‹ 2.1K - 10% open Â· â±ï¸ 20.05.2024):  \n",
      "```\n",
      "git clone https://github.com/PaddlePaddle/PaddleSeg\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/paddleseg) (ğŸ“¥ 2.6K / month):\n",
      "```\n",
      "pip install paddleseg\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/JohannesBuchner/imagehash\">ImageHash</a></b> (ğŸ¥ˆ31 Â·  â­ 3.1K) - A Python Perceptual Image Hashing Module. <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>  \n",
      "- [GitHub](https://github.com/JohannesBuchner/imagehash) (ğŸ‘¨ğŸ’» 26 Â· ğŸ”€ 330 Â· ğŸ“¦ 13K Â· ğŸ“‹ 130 - 6% open Â· â±ï¸ 20.06.2024):  \n",
      "```\n",
      "git clone https://github.com/JohannesBuchner/imagehash\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/ImageHash) (ğŸ“¥ 1.6M / month):\n",
      "```\n",
      "pip install ImageHash\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/imagehash) (ğŸ“¥ 380K Â· â±ï¸ 16.06.2023):\n",
      "```\n",
      "conda install -c conda-forge imagehash\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/lightly-ai/lightly\">lightly</a></b> (ğŸ¥ˆ31 Â·  â­ 2.8K) - A python library for self-supervised learning on images. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/lightly-ai/lightly) (ğŸ‘¨ğŸ’» 41 Â· ğŸ”€ 240 Â· ğŸ“¦ 280 Â· ğŸ“‹ 530 - 19% open Â· â±ï¸ 04.07.2024):  \n",
      "```\n",
      "git clone https://github.com/lightly-ai/lightly\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/lightly) (ğŸ“¥ 34K / month):\n",
      "```\n",
      "pip install lightly\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/lucidrains/vit-pytorch\">vit-pytorch</a></b> (ğŸ¥‰30 Â·  â­ 19K) - Implementation of Vision Transformer, a simple way to achieve.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/lucidrains/vit-pytorch) (ğŸ‘¨ğŸ’» 21 Â· ğŸ”€ 2.8K Â· ğŸ“¦ 500 Â· ğŸ“‹ 260 - 47% open Â· â±ï¸ 11.06.2024):  \n",
      "```\n",
      "git clone https://github.com/lucidrains/vit-pytorch\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/vit-pytorch) (ğŸ“¥ 15K / month):\n",
      "```\n",
      "pip install vit-pytorch\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/OlafenwaMoses/ImageAI\">imageai</a></b> (ğŸ¥‰30 Â·  â­ 8.5K) - A python library built to empower developers to build applications and.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>  \n",
      "- [GitHub](https://github.com/OlafenwaMoses/ImageAI) (ğŸ‘¨ğŸ’» 19 Â· ğŸ”€ 2.1K Â· ğŸ“¥ 930K Â· ğŸ“¦ 1.6K Â· ğŸ“‹ 740 - 39% open Â· â±ï¸ 20.02.2024):  \n",
      "```\n",
      "git clone https://github.com/OlafenwaMoses/ImageAI\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/imageai) (ğŸ“¥ 6.2K / month):\n",
      "```\n",
      "pip install imageai\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/imageai) (ğŸ“¥ 7.4K Â· â±ï¸ 16.06.2023):\n",
      "```\n",
      "conda install -c conda-forge imageai\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/obss/sahi\">sahi</a></b> (ğŸ¥‰30 Â·  â­ 3.8K) - Framework agnostic sliced/tiled inference + interactive ui + error analysis.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>  \n",
      "- [GitHub](https://github.com/obss/sahi) (ğŸ‘¨ğŸ’» 47 Â· ğŸ”€ 550 Â· ğŸ“¥ 26K Â· ğŸ“¦ 1.2K Â· â±ï¸ 01.07.2024):  \n",
      "```\n",
      "git clone https://github.com/obss/sahi\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/sahi) (ğŸ“¥ 130K / month):\n",
      "```\n",
      "pip install sahi\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/sahi) (ğŸ“¥ 63K Â· â±ï¸ 21.05.2024):\n",
      "```\n",
      "conda install -c conda-forge sahi\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/abhiTronix/vidgear\">vidgear</a></b> (ğŸ¥‰30 Â·  â­ 3.3K) - A High-performance cross-platform Video Processing Python framework.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>  \n",
      "- [GitHub](https://github.com/abhiTronix/vidgear) (ğŸ‘¨ğŸ’» 14 Â· ğŸ”€ 240 Â· ğŸ“¥ 1.4K Â· ğŸ“¦ 580 Â· ğŸ“‹ 290 - 1% open Â· â±ï¸ 22.06.2024):  \n",
      "```\n",
      "git clone https://github.com/abhiTronix/vidgear\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/vidgear) (ğŸ“¥ 14K / month):\n",
      "```\n",
      "pip install vidgear\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/1adrianb/face-alignment\">Face Alignment</a></b> (ğŸ¥‰28 Â·  â­ 6.9K Â· ğŸ’¤) - 2D and 3D Face alignment library build using pytorch. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/1adrianb/face-alignment) (ğŸ‘¨ğŸ’» 26 Â· ğŸ”€ 1.3K Â· ğŸ“¦ 21 Â· ğŸ“‹ 310 - 22% open Â· â±ï¸ 16.08.2023):  \n",
      "```\n",
      "git clone https://github.com/1adrianb/face-alignment\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/face-alignment) (ğŸ“¥ 63K / month):\n",
      "```\n",
      "pip install face-alignment\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/PaddlePaddle/PaddleDetection\">PaddleDetection</a></b> (ğŸ¥‰27 Â·  â­ 12K) - Object Detection toolkit based on PaddlePaddle. It.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1M\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/PaddlePaddle/PaddleDetection) (ğŸ‘¨ğŸ’» 160 Â· ğŸ”€ 2.8K Â· ğŸ“‹ 5.3K - 22% open Â· â±ï¸ 22.05.2024):  \n",
      "```\n",
      "git clone https://github.com/PaddlePaddle/PaddleDetection\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/paddledet) (ğŸ“¥ 600 / month):\n",
      "```\n",
      "pip install paddledet\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/mindee/doctr\">doctr</a></b> (ğŸ¥‰27 Â·  â­ 3.3K) - docTR (Document Text Recognition) - a seamless, high-.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/mindee/doctr) (ğŸ‘¨ğŸ’» 47 Â· ğŸ”€ 390 Â· ğŸ“¥ 3.2M Â· ğŸ“‹ 350 - 7% open Â· â±ï¸ 14.06.2024):  \n",
      "```\n",
      "git clone https://github.com/mindee/doctr\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/python-doctr) (ğŸ“¥ 35K / month):\n",
      "```\n",
      "pip install python-doctr\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/tryolabs/norfair\">Norfair</a></b> (ğŸ¥‰26 Â·  â­ 2.3K) - Lightweight Python library for adding real-time multi-object tracking.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code></summary>  \n",
      "- [GitHub](https://github.com/tryolabs/norfair) (ğŸ‘¨ğŸ’» 31 Â· ğŸ”€ 240 Â· ğŸ“¥ 320 Â· ğŸ“¦ 200 Â· ğŸ“‹ 160 - 10% open Â· â±ï¸ 30.01.2024):  \n",
      "```\n",
      "git clone https://github.com/tryolabs/norfair\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/norfair) (ğŸ“¥ 16K / month):\n",
      "```\n",
      "pip install norfair\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/luispedro/mahotas\">mahotas</a></b> (ğŸ¥‰26 Â·  â­ 840) - Computer Vision in Python. <code>â—Unlicensed</code></summary>  \n",
      "- [GitHub](https://github.com/luispedro/mahotas) (ğŸ‘¨ğŸ’» 35 Â· ğŸ”€ 150 Â· ğŸ“¦ 1.3K Â· ğŸ“‹ 91 - 24% open Â· â±ï¸ 03.07.2024):  \n",
      "```\n",
      "git clone https://github.com/luispedro/mahotas\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/mahotas) (ğŸ“¥ 13K / month):\n",
      "```\n",
      "pip install mahotas\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/mahotas) (ğŸ“¥ 430K Â· â±ï¸ 18.05.2024):\n",
      "```\n",
      "conda install -c conda-forge mahotas\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/CellProfiler/CellProfiler\">CellProfiler</a></b> (ğŸ¥‰25 Â·  â­ 870) - An open-source application for biological image analysis. <code>â—Unlicensed</code></summary>  \n",
      "- [GitHub](https://github.com/CellProfiler/CellProfiler) (ğŸ‘¨ğŸ’» 140 Â· ğŸ”€ 360 Â· ğŸ“¥ 7.2K Â· ğŸ“¦ 22 Â· ğŸ“‹ 3.3K - 9% open Â· â±ï¸ 01.05.2024):  \n",
      "```\n",
      "git clone https://github.com/CellProfiler/CellProfiler\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/cellprofiler) (ğŸ“¥ 660 / month):\n",
      "```\n",
      "pip install cellprofiler\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/facebookresearch/mmf\">MMF</a></b> (ğŸ¥‰24 Â·  â­ 5.4K) - A modular framework for vision & language multimodal research from.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/facebookresearch/mmf) (ğŸ‘¨ğŸ’» 120 Â· ğŸ”€ 890 Â· ğŸ“¦ 18 Â· ğŸ“‹ 650 - 16% open Â· â±ï¸ 25.05.2024):  \n",
      "```\n",
      "git clone https://github.com/facebookresearch/mmf\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/mmf) (ğŸ“¥ 210 / month):\n",
      "```\n",
      "pip install mmf\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/libffcv/ffcv\">ffcv</a></b> (ğŸ¥‰24 Â·  â­ 2.8K) - FFCV: Fast Forward Computer Vision (and other ML workloads!). <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>  \n",
      "- [GitHub](https://github.com/libffcv/ffcv) (ğŸ‘¨ğŸ’» 31 Â· ğŸ”€ 170 Â· ğŸ“¦ 49 Â· ğŸ“‹ 270 - 35% open Â· â±ï¸ 06.05.2024):  \n",
      "```\n",
      "git clone https://github.com/libffcv/ffcv\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/ffcv) (ğŸ“¥ 870 / month):\n",
      "```\n",
      "pip install ffcv\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/torch-points3d/torch-points3d\">torch-points3d</a></b> (ğŸ¥‰24 Â·  â­ 2.4K) - Pytorch framework for doing deep learning on point clouds. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/torch-points3d/torch-points3d) (ğŸ‘¨ğŸ’» 35 Â· ğŸ”€ 340 Â· ğŸ“¦ 26 Â· ğŸ“‹ 360 - 20% open Â· â±ï¸ 06.06.2024):  \n",
      "```\n",
      "git clone https://github.com/torch-points3d/torch-points3d\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/torch-points3d) (ğŸ“¥ 650 / month):\n",
      "```\n",
      "pip install torch-points3d\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/facebookresearch/vissl\">vissl</a></b> (ğŸ¥‰23 Â·  â­ 3.2K) - VISSL is FAIRs library of extensible, modular and scalable components.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/facebookresearch/vissl) (ğŸ‘¨ğŸ’» 38 Â· ğŸ”€ 320 Â· ğŸ“¦ 45 Â· ğŸ“‹ 170 - 38% open Â· â±ï¸ 03.03.2024):  \n",
      "```\n",
      "git clone https://github.com/facebookresearch/vissl\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/vissl) (ğŸ“¥ 180 / month):\n",
      "```\n",
      "pip install vissl\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/facebookresearch/pytorchvideo\">pytorchvideo</a></b> (ğŸ¥‰23 Â·  â­ 3.2K) - A deep learning library for video understanding research. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/facebookresearch/pytorchvideo) (ğŸ‘¨ğŸ’» 55 Â· ğŸ”€ 390 Â· ğŸ“‹ 180 - 43% open Â· â±ï¸ 03.03.2024):  \n",
      "```\n",
      "git clone https://github.com/facebookresearch/pytorchvideo\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/pytorchvideo) (ğŸ“¥ 33K / month):\n",
      "```\n",
      "pip install pytorchvideo\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/facebookresearch/detr\">DEâ«¶TR</a></b> (ğŸ¥‰21 Â·  â­ 13K) - End-to-End Object Detection with Transformers. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/facebookresearch/detr) (ğŸ‘¨ğŸ’» 27 Â· ğŸ”€ 2.3K Â· ğŸ“¦ 21 Â· ğŸ“‹ 530 - 45% open Â· â±ï¸ 12.03.2024):  \n",
      "```\n",
      "git clone https://github.com/facebookresearch/detr\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/facebookresearch/SlowFast\">PySlowFast</a></b> (ğŸ¥‰21 Â·  â­ 6.4K) - PySlowFast: video understanding codebase from FAIR for.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/facebookresearch/SlowFast) (ğŸ‘¨ğŸ’» 32 Â· ğŸ”€ 1.1K Â· ğŸ“¦ 17 Â· ğŸ“‹ 660 - 57% open Â· â±ï¸ 06.06.2024):  \n",
      "```\n",
      "git clone https://github.com/facebookresearch/SlowFast\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/pyslowfast) (ğŸ“¥ 27 / month):\n",
      "```\n",
      "pip install pyslowfast\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/tensorflow/graphics\">tensorflow-graphics</a></b> (ğŸ¥‰21 Â·  â­ 2.7K) - TensorFlow Graphics: Differentiable Graphics Layers.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/tensorflow/graphics) (ğŸ‘¨ğŸ’» 39 Â· ğŸ”€ 360 Â· ğŸ“‹ 180 - 48% open Â· â±ï¸ 13.03.2024):  \n",
      "```\n",
      "git clone https://github.com/tensorflow/graphics\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/tensorflow-graphics) (ğŸ“¥ 9.2K / month):\n",
      "```\n",
      "pip install tensorflow-graphics\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/google-research/kubric\">kubric</a></b> (ğŸ¥‰21 Â·  â­ 2.2K) - A data generation pipeline for creating semi-realistic synthetic.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>  \n",
      "- [GitHub](https://github.com/google-research/kubric) (ğŸ‘¨ğŸ’» 30 Â· ğŸ”€ 210 Â· ğŸ“¦ 6 Â· ğŸ“‹ 180 - 30% open Â· â±ï¸ 27.06.2024):  \n",
      "```\n",
      "git clone https://github.com/google-research/kubric\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/kubric-nightly) (ğŸ“¥ 480 / month):\n",
      "```\n",
      "pip install kubric-nightly\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/libvips/pyvips\">pyvips</a></b> (ğŸ¥‰21 Â·  â­ 610) - python binding for libvips using cffi. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>  \n",
      "- [GitHub](https://github.com/libvips/pyvips) (ğŸ‘¨ğŸ’» 16 Â· ğŸ”€ 50 Â· ğŸ“¦ 750 Â· ğŸ“‹ 420 - 42% open Â· â±ï¸ 28.04.2024):  \n",
      "```\n",
      "git clone https://github.com/libvips/pyvips\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/pyvips) (ğŸ“¥ 45K / month):\n",
      "```\n",
      "pip install pyvips\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/pyvips) (ğŸ“¥ 95K Â· â±ï¸ 28.04.2024):\n",
      "```\n",
      "conda install -c conda-forge pyvips\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/google-research/scenic\">scenic</a></b> (ğŸ¥‰18 Â·  â­ 3.1K) - Scenic: A Jax Library for Computer Vision Research and Beyond. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/google-research/scenic) (ğŸ‘¨ğŸ’» 81 Â· ğŸ”€ 410 Â· ğŸ“‹ 240 - 52% open Â· â±ï¸ 14.06.2024):  \n",
      "```\n",
      "git clone https://github.com/google-research/scenic\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/facebookresearch/NeuralCompression\">NeuralCompression</a></b> (ğŸ¥‰15 Â·  â­ 480) - A collection of tools for neural compression enthusiasts. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>  \n",
      "- [GitHub](https://github.com/facebookresearch/NeuralCompression) (ğŸ‘¨ğŸ’» 10 Â· ğŸ”€ 41 Â· ğŸ“‹ 69 - 7% open Â· â±ï¸ 18.03.2024):  \n",
      "```\n",
      "git clone https://github.com/facebookresearch/NeuralCompression\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/neuralcompression) (ğŸ“¥ 83 / month):\n",
      "```\n",
      "pip install neuralcompression\n",
      "```\n",
      "</details>\n",
      "<details><summary>Show 12 hidden projects...</summary>  \n",
      "- <b><a href=\"https://github.com/aleju/imgaug\">imgaug</a></b> (ğŸ¥ˆ36 Â·  â­ 14K Â· ğŸ’€) - Image augmentation for machine learning experiments. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n",
      "- <b><a href=\"https://github.com/ageitgey/face_recognition\">Face Recognition</a></b> (ğŸ¥ˆ32 Â·  â­ 52K Â· ğŸ’€) - The worlds simplest facial recognition api for Python.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n",
      "- <b><a href=\"https://github.com/PyImageSearch/imutils\">imutils</a></b> (ğŸ¥ˆ31 Â·  â­ 4.5K Â· ğŸ’€) - A series of convenience functions to make basic image processing.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n",
      "- <b><a href=\"https://github.com/Layout-Parser/layout-parser\">layout-parser</a></b> (ğŸ¥‰27 Â·  â­ 4.6K Â· ğŸ’€) - A Unified Toolkit for Deep Learning Based Document Image.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n",
      "- <b><a href=\"https://github.com/idealo/imagededup\">Image Deduplicator</a></b> (ğŸ¥‰25 Â·  â­ 5K Â· ğŸ’€) - Finding duplicate images made easy!. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n",
      "- <b><a href=\"https://github.com/mdbloice/Augmentor\">Augmentor</a></b> (ğŸ¥‰23 Â·  â­ 5K Â· ğŸ’€) - Image augmentation library in Python for machine learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n",
      "- <b><a href=\"https://github.com/lucidrains/deep-daze\">deep-daze</a></b> (ğŸ¥‰22 Â·  â­ 4.4K Â· ğŸ’€) - Simple command line tool for text to image generation using.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n",
      "- <b><a href=\"https://github.com/uploadcare/pillow-simd\">Pillow-SIMD</a></b> (ğŸ¥‰22 Â·  â­ 2.1K Â· ğŸ’€) - The friendly PIL fork. <code><a href=\"https://tldrlegal.com/search?q=PIL\">â—ï¸PIL</a></code>\n",
      "- <b><a href=\"https://github.com/airctic/icevision\">icevision</a></b> (ğŸ¥‰21 Â·  â­ 840 Â· ğŸ’€) - An Agnostic Computer Vision Framework - Pluggable to any.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code>\n",
      "- <b><a href=\"https://github.com/idealo/image-super-resolution\">Image Super-Resolution</a></b> (ğŸ¥‰19 Â·  â­ 4.6K Â· ğŸ’€) - Super-scale your images and run experiments with.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n",
      "- <b><a href=\"https://github.com/hhatto/nude.py\">nude.py</a></b> (ğŸ¥‰18 Â·  â­ 920 Â· ğŸ’€) - Nudity detection with Python. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n",
      "- <b><a href=\"https://github.com/jasmcaus/caer\">Caer</a></b> (ğŸ¥‰17 Â·  â­ 760 Â· ğŸ’€) - A lightweight Computer Vision library. Scale your models, not boilerplate. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code>\n",
      "</details>\n",
      "<br>\n",
      "15987\n",
      "<a href=\"#contents\"><img align=\"right\" width=\"15\" height=\"15\" src=\"https://git.io/JtehR\" alt=\"Back to top\"></a>  \n",
      "_Libraries for graph processing, clustering, embedding, and machine learning tasks._  \n",
      "<details><summary><b><a href=\"https://github.com/networkx/networkx\">networkx</a></b> (ğŸ¥‡42 Â·  â­ 14K) - Network Analysis in Python. <code>â—Unlicensed</code></summary>  \n",
      "- [GitHub](https://github.com/networkx/networkx) (ğŸ‘¨ğŸ’» 730 Â· ğŸ”€ 3.1K Â· ğŸ“¥ 71 Â· ğŸ“¦ 270K Â· ğŸ“‹ 3.2K - 5% open Â· â±ï¸ 04.07.2024):  \n",
      "```\n",
      "git clone https://github.com/networkx/networkx\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/networkx) (ğŸ“¥ 49M / month):\n",
      "```\n",
      "pip install networkx\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/networkx) (ğŸ“¥ 17M Â· â±ï¸ 08.04.2024):\n",
      "```\n",
      "conda install -c conda-forge networkx\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/pyg-team/pytorch_geometric\">PyTorch Geometric</a></b> (ğŸ¥‡41 Â·  â­ 21K) - Graph Neural Network Library for PyTorch. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/pyg-team/pytorch_geometric) (ğŸ‘¨ğŸ’» 500 Â· ğŸ”€ 3.5K Â· ğŸ“¦ 6K Â· ğŸ“‹ 3.5K - 24% open Â· â±ï¸ 03.07.2024):  \n",
      "```\n",
      "git clone https://github.com/pyg-team/pytorch_geometric\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/torch-geometric) (ğŸ“¥ 530K / month):\n",
      "```\n",
      "pip install torch-geometric\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/pytorch_geometric) (ğŸ“¥ 51K Â· â±ï¸ 04.05.2024):\n",
      "```\n",
      "conda install -c conda-forge pytorch_geometric\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/dmlc/dgl\">dgl</a></b> (ğŸ¥‡38 Â·  â­ 13K) - Python package built to ease deep learning on graph, on top of existing DL.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>  \n",
      "- [GitHub](https://github.com/dmlc/dgl) (ğŸ‘¨ğŸ’» 290 Â· ğŸ”€ 2.9K Â· ğŸ“¦ 260 Â· ğŸ“‹ 2.7K - 14% open Â· â±ï¸ 04.07.2024):  \n",
      "```\n",
      "git clone https://github.com/dmlc/dgl\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/dgl) (ğŸ“¥ 140K / month):\n",
      "```\n",
      "pip install dgl\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/igraph/python-igraph\">igraph</a></b> (ğŸ¥ˆ34 Â·  â­ 1.3K) - Python interface for igraph. <code><a href=\"http://bit.ly/2KucAZR\">â—ï¸GPL-2.0</a></code></summary>  \n",
      "- [GitHub](https://github.com/igraph/python-igraph) (ğŸ‘¨ğŸ’» 75 Â· ğŸ”€ 240 Â· ğŸ“¥ 560K Â· ğŸ“¦ 4K Â· ğŸ“‹ 550 - 7% open Â· â±ï¸ 03.07.2024):  \n",
      "```\n",
      "git clone https://github.com/igraph/python-igraph\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/python-igraph) (ğŸ“¥ 190K / month):\n",
      "```\n",
      "pip install python-igraph\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/igraph) (ğŸ“¥ 560K Â· â±ï¸ 28.06.2024):\n",
      "```\n",
      "conda install -c conda-forge igraph\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/snap-stanford/ogb\">ogb</a></b> (ğŸ¥ˆ29 Â·  â­ 1.9K) - Benchmark datasets, data loaders, and evaluators for graph machine learning. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>  \n",
      "- [GitHub](https://github.com/snap-stanford/ogb) (ğŸ‘¨ğŸ’» 32 Â· ğŸ”€ 380 Â· ğŸ“¦ 1.8K Â· ğŸ“‹ 290 - 7% open Â· â±ï¸ 01.02.2024):  \n",
      "```\n",
      "git clone https://github.com/snap-stanford/ogb\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/ogb) (ğŸ“¥ 77K / month):\n",
      "```\n",
      "pip install ogb\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/ogb) (ğŸ“¥ 33K Â· â±ï¸ 16.06.2023):\n",
      "```\n",
      "conda install -c conda-forge ogb\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/graphistry/pygraphistry\">pygraphistry</a></b> (ğŸ¥ˆ27 Â·  â­ 2.1K) - PyGraphistry is a Python library to quickly load, shape,.. <code><a href=\"http://bit.ly/3aKzpTv\">BSD-3</a></code> <code><img src=\"https://git.io/JLy1E\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/graphistry/pygraphistry) (ğŸ‘¨ğŸ’» 42 Â· ğŸ”€ 200 Â· ğŸ“¦ 120 Â· ğŸ“‹ 310 - 48% open Â· â±ï¸ 30.04.2024):  \n",
      "```\n",
      "git clone https://github.com/graphistry/pygraphistry\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/graphistry) (ğŸ“¥ 2.6K / month):\n",
      "```\n",
      "pip install graphistry\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/danielegrattarola/spektral\">Spektral</a></b> (ğŸ¥ˆ26 Â·  â­ 2.4K) - Graph Neural Networks with Keras and Tensorflow 2. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/danielegrattarola/spektral) (ğŸ‘¨ğŸ’» 27 Â· ğŸ”€ 330 Â· ğŸ“¦ 300 Â· ğŸ“‹ 280 - 24% open Â· â±ï¸ 21.01.2024):  \n",
      "```\n",
      "git clone https://github.com/danielegrattarola/spektral\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/spektral) (ğŸ“¥ 7.5K / month):\n",
      "```\n",
      "pip install spektral\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/Accenture/AmpliGraph\">AmpliGraph</a></b> (ğŸ¥ˆ26 Â·  â­ 2.1K Â· ğŸ“‰) - Python library for Representation Learning on Knowledge.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/Accenture/AmpliGraph) (ğŸ‘¨ğŸ’» 21 Â· ğŸ”€ 250 Â· ğŸ“¦ 52 Â· ğŸ“‹ 220 - 15% open Â· â±ï¸ 28.02.2024):  \n",
      "```\n",
      "git clone https://github.com/Accenture/AmpliGraph\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/ampligraph) (ğŸ“¥ 870 / month):\n",
      "```\n",
      "pip install ampligraph\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/pykeen/pykeen\">PyKEEN</a></b> (ğŸ¥ˆ25 Â·  â­ 1.6K) - A Python library for learning and evaluating knowledge graph embeddings. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>  \n",
      "- [GitHub](https://github.com/pykeen/pykeen) (ğŸ‘¨ğŸ’» 40 Â· ğŸ”€ 180 Â· ğŸ“¥ 190 Â· ğŸ“‹ 540 - 16% open Â· â±ï¸ 25.06.2024):  \n",
      "```\n",
      "git clone https://github.com/pykeen/pykeen\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/pykeen) (ğŸ“¥ 4.7K / month):\n",
      "```\n",
      "pip install pykeen\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/PaddlePaddle/PGL\">Paddle Graph Learning</a></b> (ğŸ¥ˆ25 Â·  â­ 1.6K Â· ğŸ’¤) - Paddle Graph Learning (PGL) is an efficient and.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1M\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/PaddlePaddle/PGL) (ğŸ‘¨ğŸ’» 31 Â· ğŸ”€ 310 Â· ğŸ“¦ 59 Â· ğŸ“‹ 190 - 20% open Â· â±ï¸ 26.09.2023):  \n",
      "```\n",
      "git clone https://github.com/PaddlePaddle/PGL\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/pgl) (ğŸ“¥ 900 / month):\n",
      "```\n",
      "pip install pgl\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/benedekrozemberczki/pytorch_geometric_temporal\">pytorch_geometric_temporal</a></b> (ğŸ¥ˆ24 Â·  â­ 2.6K Â· ğŸ’¤) - PyTorch Geometric Temporal: Spatiotemporal Signal.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/benedekrozemberczki/pytorch_geometric_temporal) (ğŸ‘¨ğŸ’» 28 Â· ğŸ”€ 360 Â· ğŸ“‹ 180 - 14% open Â· â±ï¸ 01.07.2023):  \n",
      "```\n",
      "git clone https://github.com/benedekrozemberczki/pytorch_geometric_temporal\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/torch-geometric-temporal) (ğŸ“¥ 2K / month):\n",
      "```\n",
      "pip install torch-geometric-temporal\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/benedekrozemberczki/karateclub\">Karate Club</a></b> (ğŸ¥ˆ24 Â·  â­ 2.1K) - Karate Club: An API Oriented Open-source Python Framework for.. <code><a href=\"http://bit.ly/2M0xdwT\">â—ï¸GPL-3.0</a></code></summary>  \n",
      "- [GitHub](https://github.com/benedekrozemberczki/karateclub) (ğŸ‘¨ğŸ’» 20 Â· ğŸ”€ 240 Â· ğŸ“¦ 240 Â· ğŸ“‹ 120 - 5% open Â· â±ï¸ 05.03.2024):  \n",
      "```\n",
      "git clone https://github.com/benedekrozemberczki/karateclub\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/karateclub) (ğŸ“¥ 3.8K / month):\n",
      "```\n",
      "pip install karateclub\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/karateclub) (ğŸ“¥ 24K Â· â±ï¸ 16.06.2023):\n",
      "```\n",
      "conda install -c conda-forge karateclub\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/eliorc/node2vec\">Node2Vec</a></b> (ğŸ¥ˆ24 Â·  â­ 1.2K) - Implementation of the node2vec algorithm. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>  \n",
      "- [GitHub](https://github.com/eliorc/node2vec) (ğŸ‘¨ğŸ’» 15 Â· ğŸ”€ 230 Â· ğŸ“¦ 640 Â· ğŸ“‹ 92 - 5% open Â· â±ï¸ 05.05.2024):  \n",
      "```\n",
      "git clone https://github.com/eliorc/node2vec\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/node2vec) (ğŸ“¥ 14K / month):\n",
      "```\n",
      "pip install node2vec\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/node2vec) (ğŸ“¥ 29K Â· â±ï¸ 16.06.2023):\n",
      "```\n",
      "conda install -c conda-forge node2vec\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/facebookresearch/PyTorch-BigGraph\">PyTorch-BigGraph</a></b> (ğŸ¥‰22 Â·  â­ 3.4K) - Generate embeddings from large-scale graph-structured.. <code>â—Unlicensed</code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/facebookresearch/PyTorch-BigGraph) (ğŸ‘¨ğŸ’» 32 Â· ğŸ”€ 440 Â· ğŸ“¥ 190 Â· ğŸ“‹ 200 - 30% open Â· â±ï¸ 03.03.2024):  \n",
      "```\n",
      "git clone https://github.com/facebookresearch/PyTorch-BigGraph\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/torchbiggraph) (ğŸ“¥ 500K / month):\n",
      "```\n",
      "pip install torchbiggraph\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/pygod-team/pygod\">pygod</a></b> (ğŸ¥‰22 Â·  â­ 1.3K) - A Python Library for Graph Outlier Detection (Anomaly Detection). <code><a href=\"http://bit.ly/3rqEWVr\">BSD-2</a></code></summary>  \n",
      "- [GitHub](https://github.com/pygod-team/pygod) (ğŸ‘¨ğŸ’» 16 Â· ğŸ”€ 130 Â· ğŸ“¦ 29 Â· ğŸ“‹ 59 - 6% open Â· â±ï¸ 23.06.2024):  \n",
      "```\n",
      "git clone https://github.com/pygod-team/pygod\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/pygod) (ğŸ“¥ 790 / month):\n",
      "```\n",
      "pip install pygod\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/pygod) (ğŸ“¥ 5.3K Â· â±ï¸ 05.02.2024):\n",
      "```\n",
      "conda install -c conda-forge pygod\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/IBCNServices/pyRDF2Vec\">pyRDF2Vec</a></b> (ğŸ¥‰21 Â·  â­ 240 Â· ğŸ’¤) - Python Implementation and Extension of RDF2Vec. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>  \n",
      "- [GitHub](https://github.com/IBCNServices/pyRDF2Vec) (ğŸ‘¨ğŸ’» 7 Â· ğŸ”€ 45 Â· ğŸ“¦ 44 Â· ğŸ“‹ 85 - 24% open Â· â±ï¸ 02.07.2023):  \n",
      "```\n",
      "git clone https://github.com/IBCNServices/pyRDF2Vec\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/pyrdf2vec) (ğŸ“¥ 250 / month):\n",
      "```\n",
      "pip install pyrdf2vec\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/divelab/DIG\">DIG</a></b> (ğŸ¥‰20 Â·  â­ 1.8K) - A library for graph deep learning research. <code><a href=\"http://bit.ly/2M0xdwT\">â—ï¸GPL-3.0</a></code></summary>  \n",
      "- [GitHub](https://github.com/divelab/DIG) (ğŸ‘¨ğŸ’» 50 Â· ğŸ”€ 270 Â· ğŸ“‹ 200 - 13% open Â· â±ï¸ 04.02.2024):  \n",
      "```\n",
      "git clone https://github.com/divelab/DIG\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/dig) (ğŸ“¥ 500 / month):\n",
      "```\n",
      "pip install dig\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/snap-stanford/deepsnap\">deepsnap</a></b> (ğŸ¥‰20 Â·  â­ 540 Â· ğŸ’¤) - Python library assists deep learning on graphs. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code></summary>  \n",
      "- [GitHub](https://github.com/snap-stanford/deepsnap) (ğŸ‘¨ğŸ’» 18 Â· ğŸ”€ 57 Â· ğŸ“¥ 12 Â· ğŸ“¦ 100 Â· ğŸ“‹ 48 - 47% open Â· â±ï¸ 11.11.2023):  \n",
      "```\n",
      "git clone https://github.com/snap-stanford/deepsnap\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/deepsnap) (ğŸ“¥ 380 / month):\n",
      "```\n",
      "pip install deepsnap\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/rusty1s/pytorch_cluster\">torch-cluster</a></b> (ğŸ¥‰19 Â·  â­ 780) - PyTorch Extension Library of Optimized Graph Cluster.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/rusty1s/pytorch_cluster) (ğŸ‘¨ğŸ’» 34 Â· ğŸ”€ 140 Â· ğŸ“‹ 160 - 18% open Â· â±ï¸ 29.04.2024):  \n",
      "```\n",
      "git clone https://github.com/rusty1s/pytorch_cluster\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/torch-cluster) (ğŸ“¥ 12K / month):\n",
      "```\n",
      "pip install torch-cluster\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/pytorch_cluster) (ğŸ“¥ 130K Â· â±ï¸ 17.05.2024):\n",
      "```\n",
      "conda install -c conda-forge pytorch_cluster\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/deepgraph/deepgraph\">DeepGraph</a></b> (ğŸ¥‰17 Â·  â­ 280) - Analyze Data with Pandas-based Networks. Documentation:. <code>â—Unlicensed</code> <code><img src=\"https://git.io/JLy1S\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/deepgraph/deepgraph) (ğŸ‘¨ğŸ’» 3 Â· ğŸ”€ 41 Â· ğŸ“¦ 10 Â· ğŸ“‹ 18 - 55% open Â· â±ï¸ 27.03.2024):  \n",
      "```\n",
      "git clone https://github.com/deepgraph/deepgraph\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/deepgraph) (ğŸ“¥ 690 / month):\n",
      "```\n",
      "pip install deepgraph\n",
      "```\n",
      "- [Conda](https://anaconda.org/conda-forge/deepgraph) (ğŸ“¥ 190K Â· â±ï¸ 27.03.2024):\n",
      "```\n",
      "conda install -c conda-forge deepgraph\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/vaticle/typedb-ml\">typedb-ml</a></b> (ğŸ¥‰16 Â·  â­ 550 Â· ğŸ’¤) - TypeDB-ML is the Machine Learning integrations library for.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>  \n",
      "- [GitHub](https://github.com/vaticle/typedb-ml) (ğŸ‘¨ğŸ’» 12 Â· ğŸ”€ 90 Â· ğŸ“¥ 230 Â· ğŸ“‹ 63 - 19% open Â· â±ï¸ 18.11.2023):  \n",
      "```\n",
      "git clone https://github.com/vaticle/typedb-ml\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/typedb-ml) (ğŸ“¥ 18 / month):\n",
      "```\n",
      "pip install typedb-ml\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/DeepGraphLearning/graphvite\">GraphVite</a></b> (ğŸ¥‰15 Â·  â­ 1.2K) - GraphVite: A General and High-performance Graph Embedding System. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>  \n",
      "- [GitHub](https://github.com/DeepGraphLearning/graphvite) (ğŸ”€ 150 Â· ğŸ“‹ 110 - 47% open Â· â±ï¸ 14.06.2024):  \n",
      "```\n",
      "git clone https://github.com/DeepGraphLearning/graphvite\n",
      "```\n",
      "- [Conda](https://anaconda.org/milagraph/graphvite) (ğŸ“¥ 4.7K Â· â±ï¸ 16.06.2023):\n",
      "```\n",
      "conda install -c milagraph graphvite\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/THUMNLab/AutoGL\">AutoGL</a></b> (ğŸ¥‰15 Â·  â­ 1.1K) - An autoML framework & toolkit for machine learning on graphs. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/THUMNLab/AutoGL) (ğŸ‘¨ğŸ’» 15 Â· ğŸ”€ 120 Â· ğŸ“‹ 39 - 35% open Â· â±ï¸ 05.02.2024):  \n",
      "```\n",
      "git clone https://github.com/THUMNLab/AutoGL\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/auto-graph-learning):\n",
      "```\n",
      "pip install auto-graph-learning\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/thunlp/OpenNE\">OpenNE</a></b> (ğŸ¥‰14 Â·  â­ 1.7K) - An Open-Source Package for Network Embedding (NE). <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>  \n",
      "- [GitHub](https://github.com/thunlp/OpenNE) (ğŸ‘¨ğŸ’» 12 Â· ğŸ”€ 480 Â· ğŸ“‹ 100 - 4% open Â· â±ï¸ 10.01.2024):  \n",
      "```\n",
      "git clone https://github.com/thunlp/OpenNE\n",
      "```\n",
      "</details>\n",
      "<details><summary><b><a href=\"https://github.com/thunlp/OpenKE\">OpenKE</a></b> (ğŸ¥‰13 Â·  â­ 3.8K) - An Open-Source Package for Knowledge Embedding (KE). <code>â—Unlicensed</code></summary>  \n",
      "- [GitHub](https://github.com/thunlp/OpenKE) (ğŸ‘¨ğŸ’» 14 Â· ğŸ”€ 970 Â· ğŸ“‹ 380 - 6% open Â· â±ï¸ 10.01.2024):  \n",
      "```\n",
      "git clone https://github.com/thunlp/OpenKE\n",
      "```\n",
      "</details>\n",
      "<details><summary>Show 4 hidden projects...</summary>  \n",
      "- <b><a href=\"https://github.com/stellargraph/stellargraph\">StellarGraph</a></b> (ğŸ¥ˆ27 Â·  â­ 2.9K Â· ğŸ’€) - StellarGraph - Machine Learning on Graphs. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1A\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n",
      "- <b><a href=\"https://github.com/graph4ai/graph4nlp\">graph4nlp</a></b> (ğŸ¥‰22 Â·  â­ 1.7K Â· ğŸ’€) - Graph4nlp is the library for the easy use of Graph.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://git.io/JLy1Q\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n",
      "- <b><a href=\"https://github.com/google-deepmind/jraph\">jraph</a></b> (ğŸ¥‰22 Â·  â­ 1.3K Â· ğŸ’€) - A Graph Neural Network Library in Jax. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n",
      "- <b><a href=\"https://github.com/shenweichen/GraphEmbedding\">GraphEmbedding</a></b> (ğŸ¥‰16 Â·  â­ 3.6K Â· ğŸ’€) - Implementation and experiments of graph embedding.. <code><a href=\"http://bit.ly/34MBwT8\">MIT</a></code> <code><img src=\"https://git.io/JLy1F\" style=\"display:inline;\" width=\"13\" height=\"13\"></code>\n",
      "</details>\n",
      "<br>\n"
     ]
    }
   ],
   "source": [
    "for header in md_header_splits[12:14]:\n",
    "    print(len(header.page_content))\n",
    "    print(header.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "36ec5fdc-ea1f-49f5-8baa-74e57f06954d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=250, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "07cf72db-85af-4a3f-b5ae-50040d5b321c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "texts = text_splitter.split_documents(md_header_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "bf5c0551-541d-4055-b1a5-999fb3d18de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2130"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "adc6c322-eadc-4e49-9689-9309f0682c29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "<details><summary><b><a href=\"https://github.com/jina-ai/jina\">Jina</a></b> (ğŸ¥ˆ38 Â·  â­ 21K) - Build multimodal AI applications with cloud-native stack. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code></summary>\n",
      "240\n",
      "- [GitHub](https://github.com/jina-ai/jina) (ğŸ‘¨ğŸ’» 180 Â· ğŸ”€ 2.2K Â· ğŸ“¦ 1.7K Â· ğŸ“‹ 1.9K - 0% open Â· â±ï¸ 13.06.2024):  \n",
      "```\n",
      "git clone https://github.com/jina-ai/jina\n",
      "```\n",
      "- [PyPi](https://pypi.org/project/jina) (ğŸ“¥ 92K / month):\n",
      "```\n",
      "pip install jina\n",
      "```\n",
      "242\n",
      "- [Conda](https://anaconda.org/conda-forge/jina-core) (ğŸ“¥ 68K Â· â±ï¸ 16.06.2023):\n",
      "```\n",
      "conda install -c conda-forge jina-core\n",
      "```\n",
      "- [Docker Hub](https://hub.docker.com/r/jinaai/jina) (ğŸ“¥ 1.6M Â· â­ 8 Â· â±ï¸ 13.06.2024):\n",
      "```\n",
      "docker pull jinaai/jina\n",
      "```\n",
      "10\n",
      "</details>\n",
      "225\n",
      "<details><summary><b><a href=\"https://github.com/google/flax\">Flax</a></b> (ğŸ¥ˆ38 Â·  â­ 5.8K) - Flax is a neural network library for JAX that is designed for.. <code><a href=\"http://bit.ly/3nYMfla\">Apache-2</a></code> <code><img\n",
      "127\n",
      "src=\"https://jax.readthedocs.io/en/latest/_static/favicon.png\" style=\"display:inline;\" width=\"13\" height=\"13\"></code></summary>\n"
     ]
    }
   ],
   "source": [
    "for text in texts[123:129]:\n",
    "    print(len(text.page_content))\n",
    "    print(text.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "50b91582-6d73-457d-8350-c6adeef2300b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Header 2': 'Text Data & NLP'}"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[400].metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "5217f69c-aeaf-417e-9a46-c80db8cfb024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Header 2': 'Text Data & NLP'}"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts[401].metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262f7b3-4399-405b-b1b6-f9d588080ead",
   "metadata": {},
   "source": [
    "# Recursive Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "id": "3df27863-713e-407f-8dc4-39793badbf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter, Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "id": "28e9ac65-088a-466f-a86e-ea9e48b3669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "PYTHON_CODE = \"\"\"\n",
    "def add(a, b):\n",
    "    return a + b\n",
    "\n",
    "class Calculator:\n",
    "    def __init__(self):\n",
    "        self.result = 0\n",
    "\n",
    "    def add(self, value):\n",
    "        self.result += value\n",
    "        return self.result\n",
    "\n",
    "    def subtract(self, value):\n",
    "        self.result -= value\n",
    "        return self.result\n",
    "\n",
    "# Call the function\n",
    "def main():\n",
    "    calc = Calculator()\n",
    "    print(calc.add(5))\n",
    "    print(calc.subtract(2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "2e08cafc-92db-44ea-a72b-327666257563",
   "metadata": {},
   "outputs": [],
   "source": [
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=100, chunk_overlap=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "9cec3a14-7445-4cbf-a598-7bec72eac3bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='def add(a, b):\\n    return a + b'),\n",
       " Document(page_content='class Calculator:\\n    def __init__(self):\\n        self.result = 0'),\n",
       " Document(page_content='def add(self, value):\\n        self.result += value\\n        return self.result'),\n",
       " Document(page_content='def subtract(self, value):\\n        self.result -= value\\n        return self.result'),\n",
       " Document(page_content='# Call the function'),\n",
       " Document(page_content='def main():\\n    calc = Calculator()\\n    print(calc.add(5))\\n    print(calc.subtract(2))'),\n",
       " Document(page_content='if __name__ == \"__main__\":\\n    main()')]"
      ]
     },
     "execution_count": 346,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "python_docs = python_splitter.create_documents([PYTHON_CODE])\n",
    "python_docs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81f5f35a-612a-4b12-aa6b-fc2fa3c37d9b",
   "metadata": {},
   "source": [
    "# JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "69989930-0743-4437-adea-a3ea339b89de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "id": "37e6eff7-92c3-4e17-bd16-5412d5b82036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a large nested json object and will be loaded as a python dict\n",
    "json_data = requests.get(\"https://api.smith.langchain.com/openapi.json\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "id": "c4e2eb72-505e-445a-b77e-355bffc0d033",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['openapi', 'info', 'paths', 'components'])"
      ]
     },
     "execution_count": 481,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "id": "c0e15ba3-a374-47fe-b0eb-76c56d4d1dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "id": "8ee2bb83-77f8-456a-b8fe-5b202c1e08c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_splitter = RecursiveJsonSplitter(max_chunk_size=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "id": "b303bb0a-63d9-4350-8c85-709b7f185ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_chunks = json_splitter.split_json(json_data=json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "id": "771d6f0b-7780-4905-a89d-f918704a46ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797"
      ]
     },
     "execution_count": 485,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 486,
   "id": "92762b0c-9d21-4b3b-be76-eab61d74cd87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "{'openapi': '3.1.0', 'info': {'title': 'LangSmith', 'version': '0.1.0'}, 'paths': {'/api/v1/sessions/{session_id}': {'get': {'tags': ['tracer-sessions'], 'summary': 'Read Tracer Session', 'description': 'Get a specific session.', 'operationId': 'read_tracer_session_api_v1_sessions__session_id__get', 'security': [{'API Key': []}, {'Tenant ID': []}, {'Bearer Auth': []}]}}}}\n",
      "1\n",
      "{'paths': {'/api/v1/sessions/{session_id}': {'get': {'parameters': [{'name': 'session_id', 'in': 'path', 'required': True, 'schema': {'type': 'string', 'format': 'uuid', 'title': 'Session Id'}}, {'name': 'include_stats', 'in': 'query', 'required': False, 'schema': {'type': 'boolean', 'default': False, 'title': 'Include Stats'}}, {'name': 'accept', 'in': 'header', 'required': False, 'schema': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Accept'}}]}}}}\n",
      "1\n",
      "{'paths': {'/api/v1/sessions/{session_id}': {'get': {'responses': {'200': {'description': 'Successful Response', 'content': {'application/json': {'schema': {'$ref': '#/components/schemas/TracerSession'}}}}, '422': {'description': 'Validation Error', 'content': {'application/json': {'schema': {'$ref': '#/components/schemas/HTTPValidationError'}}}}}}}}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in json_chunks[:3]:\n",
    "    print(len(chunk))\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "id": "ff0923e6-0ab5-40b6-b3c0-e50646d0b649",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_docs = json_splitter.create_documents(texts=[json_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "id": "e4a1342f-adfa-4b04-b973-259cf658c686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "797"
      ]
     },
     "execution_count": 488,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "id": "7bb9a6f1-44e4-4cc6-9526-75679b3a5112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='{\"paths\": {\"/api/v1/sessions/{session_id}\": {\"patch\": {\"tags\": [\"tracer-sessions\"], \"summary\": \"Update Tracer Session\", \"description\": \"Create a new session.\", \"operationId\": \"update_tracer_session_api_v1_sessions__session_id__patch\", \"security\": [{\"API Key\": []}, {\"Tenant ID\": []}, {\"Bearer Auth\": []}], \"parameters\": [{\"name\": \"session_id\", \"in\": \"path\", \"required\": true, \"schema\": {\"type\": \"string\", \"format\": \"uuid\", \"title\": \"Session Id\"}}]}}}}')"
      ]
     },
     "execution_count": 489,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_docs[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 518,
   "id": "d5fc74c2-bbad-4f2c-b3e9-d5c1d2652565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84\n",
      "{\"company\": {\"name\": \"TechCorp\", \"location\": {\"city\": \"Metropolis\", \"state\": \"NY\"}}}\n",
      "183\n",
      "{\"company\": {\"departments\": {\"0\": {\"name\": \"Research\", \"employees\": {\"0\": {\"name\": \"Alice\", \"age\": 30, \"role\": \"Scientist\"}, \"1\": {\"name\": \"Bob\", \"age\": 25, \"role\": \"Technician\"}}}}}}\n",
      "188\n",
      "{\"company\": {\"departments\": {\"1\": {\"name\": \"Development\", \"employees\": {\"0\": {\"name\": \"Charlie\", \"age\": 35, \"role\": \"Engineer\"}, \"1\": {\"name\": \"David\", \"age\": 28, \"role\": \"Developer\"}}}}}}\n",
      "70\n",
      "{\"financials\": {\"year\": 2023, \"revenue\": 1000000, \"expenses\": 750000}}\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveJsonSplitter\n",
    "\n",
    "# Example JSON object\n",
    "json_data = {\n",
    "    \"company\": {\n",
    "        \"name\": \"TechCorp\",\n",
    "        \"location\": {\n",
    "            \"city\": \"Metropolis\",\n",
    "            \"state\": \"NY\"\n",
    "        },\n",
    "        \"departments\": [\n",
    "            {\n",
    "                \"name\": \"Research\",\n",
    "                \"employees\": [\n",
    "                    {\"name\": \"Alice\", \"age\": 30, \"role\": \"Scientist\"},\n",
    "                    {\"name\": \"Bob\", \"age\": 25, \"role\": \"Technician\"}\n",
    "                ]\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"Development\",\n",
    "                \"employees\": [\n",
    "                    {\"name\": \"Charlie\", \"age\": 35, \"role\": \"Engineer\"},\n",
    "                    {\"name\": \"David\", \"age\": 28, \"role\": \"Developer\"}\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    \"financials\": {\n",
    "        \"year\": 2023,\n",
    "        \"revenue\": 1000000,\n",
    "        \"expenses\": 750000\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Initialize the RecursiveJsonSplitter with a maximum chunk size\n",
    "splitter = RecursiveJsonSplitter(max_chunk_size=200, min_chunk_size=20)\n",
    "\n",
    "# Split the JSON object\n",
    "chunks = splitter.split_text(json_data, convert_lists=True)\n",
    "\n",
    "# Process the chunks as needed\n",
    "for chunk in chunks:\n",
    "    print(len(chunk))\n",
    "    print(chunk)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7c5f3e0-bf47-465a-9873-60f54c44639f",
   "metadata": {},
   "source": [
    "# Semantic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bcd48231-25f7-4d8c-8a4d-c06da14b4d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import WikipediaLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f34aba19-9dcc-4747-bdfb-dab6e4374a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_experimental.text_splitter import SemanticChunker\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "903f5ff3-464b-4457-ab0d-a2afc63f2243",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WikipediaLoader(query='Generative AI', load_max_docs=1, doc_content_chars_max=5000, load_all_available_meta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b8aac0ff-1b5c-491f-8be9-e9b0125153ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7584311d-1e12-4be9-b01b-b28d93eace5e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative artificial intelligence'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].metadata['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "69e7638f-0bcc-4811-891f-4e64986b41ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Generative artificial intelligence (generative AI, GenAI, or GAI) is artificial intelligence capable of generating text, images, videos, or other data using generative models, often in response to prompts. Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics.\\nImprovements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora. Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\\nGenerative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs.\\n\\nThe academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since. Since its inception, researchers in the field have raised philosophical and ethical arguments about the nature of the human mind and the consequences of creating artificial beings with human-like intelligence; these issues have previously been explored by myth, fiction and philosophy since antiquity. The concept of automated art dates back at least to the automata of ancient Greek civilization, where inventors such as Daedalus and Hero of Alexandria were described as having designed machines capable of writing text, generating sounds, and playing music. The tradition of creative automatons has flourished throughout history, exemplified by Maillardet\\'s automaton created in the early 1800s.\\nArtificial Intelligence is an idea that has been captivating society since the mid-20th century. It began with science fiction familiarizing the world with the concept but the idea was not fully seen in the scientific manner until Alan Turing, a polymath, was curious about the feasibility of the concept. Turing\\'s groundbreaking 1950 paper, \"Computing Machinery and Intelligence,\" posed fundamental questions about machine reasoning similar to human intelligence, significantly contributing to the conceptual groundwork of AI. The development of AI was not very rapid at first because of the high costs and the fact that computers were not able to store commands. This changed during the 1956 Dartmouth Summer Research Project on AI where there was an inspiring call for AI research, setting the precedent for two decades of rapid advancements in the field.\\nSince the founding of AI in the 1950s, artists and researchers have used artificial intelligence to create artistic works. By the early 1970s, Harold Cohen was creating and exhibiting generative AI works created by AARON, the computer program Cohen created to generate paintings.\\nMarkov chains have long been used to model natural languages since their development by Russian mathematician Andrey Markov in the early 20th century. Markov published his first paper on the topic in 1906, and analyzed the pattern of vowels and consonants in the novel Eugeny Onegin using Markov chains. Once a Markov chain is learned on a text corpus, it can then be used as a probabilistic text generator.\\nThe field of machine learning often uses statistical models, including generative models, to model and predict data. Beginning in the late 2000s, the emergence of deep learning drove progress and research in image classification, speech recognition, natural language processing and other tasks. Neural networks in this era were typically trained as discriminative models, due to the difficulty of generative modeling.\\nIn 2014, advancements such as the variational autoencoder and generative adversarial network produced the first practical deep neural networks capable of learning generative models, as opposed to discriminative ones, for complex data such as images. These deep generative models were the first to output not only class labels for images but also entire images.\\nIn 2017, the Transformer network enabled advancements in generative models compared to older Long-Short Term Memory models, leading to the first generative pre-trained transformer (GPT), known as GPT-1, in 2018. This was followed in 2019 by GPT-2 which demonstrated the ability to generalize unsupervised to many different tasks as a Foundation model.\\nIn 2021, the release of DALL-E, a transformer-based pixel generative model, followed by Midjourney and Stable Diffusion marked'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5029f595-7279-4c34-864f-d0693e7a2bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_splitter = SemanticChunker(OpenAIEmbeddings(model='text-embedding-3-small'), buffer_size=1,\n",
    "                                    breakpoint_threshold_type='percentile', breakpoint_threshold_amount=70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "937cf86b-f4b4-4de1-a983-b54a6468fe02",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = semantic_splitter.create_documents([data[0].page_content])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e2dda49-3514-4ff1-80fa-67908b168622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "78192d5f-717c-47cf-a485-0e59cf958fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "874\n",
      "Generative artificial intelligence (generative AI, GenAI, or GAI) is artificial intelligence capable of generating text, images, videos, or other data using generative models, often in response to prompts. Generative AI models learn the patterns and structure of their input training data and then generate new data that has similar characteristics. Improvements in transformer-based deep neural networks, particularly large language models (LLMs), enabled an AI boom of generative AI systems in the early 2020s. These include chatbots such as ChatGPT, Copilot, Gemini and LLaMA, text-to-image artificial intelligence image generation systems such as Stable Diffusion, Midjourney and DALL-E, and text-to-video AI generators such as Sora. Companies such as OpenAI, Anthropic, Microsoft, Google, and Baidu as well as numerous smaller firms have developed generative AI models.\n",
      "621\n",
      "Generative AI has uses across a wide range of industries, including software development, healthcare, finance, entertainment, customer service, sales and marketing, art, writing, fashion, and product design. However, concerns have been raised about the potential misuse of generative AI such as cybercrime, the use of fake news or deepfakes to deceive or manipulate people, and the mass replacement of human jobs. The academic discipline of artificial intelligence was established at a research workshop held at Dartmouth College in 1956 and has experienced several waves of advancement and optimism in the decades since.\n"
     ]
    }
   ],
   "source": [
    "for text in texts[:2]:\n",
    "    print(len(text.page_content))\n",
    "    print(text.page_content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
